{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"J1BQzAonG4IK"},"outputs":[],"source":["# import the necessary packages\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNetV2 #neural network, light enough for mobile devices as well.\n","from tensorflow.keras.layers import AveragePooling2D # a filter that averages using neighbourhood points of a image.\n","from tensorflow.keras.layers import Dropout #this layer prevents overfitting of a model.\n","from tensorflow.keras.layers import Flatten #flattens a tensor/image into one dimension so that to input into dense layers.\n","from tensorflow.keras.layers import Dense # this is the neural network of the deep learning architecture.\n","from tensorflow.keras.layers import Input #its the input side of dense layer \n","from tensorflow.keras.models import Model #provides the model for training.\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np   ##handles matrix operations in optimized manner.\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ML7-hqVsSLu9"},"outputs":[],"source":["from tensorflow.keras.layers import MaxPooling2D"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4ouP-YXO675"},"outputs":[],"source":["# initialize the initial learning rate, number of epochs to train for,\n","# and batch size\n","INIT_LR = 1e-4\n","EPOCHS = 75\n","BS = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0AEzdof7Byv"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4OAuVNW8FJb"},"outputs":[],"source":["!ls '/content/drive/MyDrive'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVDkld0wPDcK"},"outputs":[],"source":["#data set directory.\n","DIRECTORY = r\"drive/MyDrive/dataset\"\n","#categorize the two image sets,\n","CATEGORIES = [\"with_smile\", \"without_smile\"]\n","\n","# grab the list of images in our dataset directory, then initialize\n","# the list of data (i.e., images) and class images\n","print(\"[INFO] loading images...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hwIJrY3mPc7Y"},"outputs":[],"source":["#empty arrays to store image data and image labels.\n","data = []\n","labels = [] # with smile and without smile.\n","\n","for category in CATEGORIES:\n","\t#accesses with simle image folder and without smile for each category\n","    path = os.path.join(DIRECTORY, category)\n","    for img in os.listdir(path):\n","      img_path = os.path.join(path, img)\n","      image = load_img(img_path, target_size=(224, 224))\n","      image = img_to_array(image)\n","      image = preprocess_input(image)\n","      data.append(image)\n","      labels.append(category)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUpoihTTPwTc"},"outputs":[],"source":["# perform one-hot encoding on the labels\n","lb = LabelBinarizer() ##calling labelBinarizer class.\n","labels = lb.fit_transform(labels) ##converts into binary labels.\n","labels = to_categorical(labels)   ##for tensorflow to understand.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h7OSJTOOP2zh"},"outputs":[],"source":["##converts into numpy arrays.\n","data = np.array(data, dtype=\"float32\")\n","labels = np.array(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"krZ-pLxFREgN"},"outputs":[],"source":["(trainX, testX, trainY, testY) = train_test_split(data, labels,\n","\ttest_size=0.20, stratify=labels, random_state=42) ##only 0.2 or 20% is used for testing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCRdhuKRP8pg"},"outputs":[],"source":["##so that the model can undertand human face with non ideal camera configurations.\n","aug = ImageDataGenerator(\n","\trotation_range=20,\n","\tzoom_range=0.15,\n","\twidth_shift_range=0.2,\n","\theight_shift_range=0.2,\n","\tshear_range=0.15,\n","\thorizontal_flip=True,\n","\tfill_mode=\"nearest\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FO5ITJODQCMd"},"outputs":[],"source":["# load the MobileNetV2 network, ensuring the head FC layer sets are\n","# left off\n","baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n","\tinput_tensor=Input(shape=(224, 224, 3))) ##224 224 is image size and 3 is color channel., RBG\n","#baseModel.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IP-br4ndQGvf"},"outputs":[],"source":["# construct the head of the model that will be placed on top of the\n","# the base model\n","headModel = baseModel.output\n","headModel = AveragePooling2D(pool_size=(5, 5))(headModel)\n","headModel = Flatten(name=\"flatten\")(headModel) ##flattens the 2D array into 1 dimension,\n","headModel = Dense(256, activation=\"relu\")(headModel) ##an activation function, rectified linera unit.\n","headModel = Dropout(0.4)(headModel) #Dropout is a regularization method used in artificial neural networks that reduces the risk of overfitting .\n","#headModel = Dense(128, activation=\"relu\")(headModel)\n","#headModel = Dropout(0.4)(headModel)\n","# headModel = Dense(30, activation=\"relu\")(headModel)\n","headModel = Dense(2, activation=\"softmax\")(headModel)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBrHAGIG3AQZ"},"outputs":[],"source":["maxModel = baseModel.output\n","maxModel = MaxPooling2D(pool_size=(5,5))(maxModel)\n","maxModel = Flatten(name=\"flatten\")(maxModel)\n","maxModel = Dense(256, activation=\"relu\")(maxModel)\n","maxModel = Dropout(0.4)(maxModel)\n","maxModel = Dense(2, activation=\"softmax\")(maxModel)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLejuwlGQL2g"},"outputs":[],"source":["# loop over all layers in the base model and freeze them so they will\n","# *not* be updated during the first training process\n","for layer in baseModel.layers:\n","\tlayer.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e3nRmnSpQnSR"},"outputs":[],"source":["# place the head FC model on top of the base model (this will become\n","# the actual model we will train)\n","model = Model(inputs=baseModel.input, outputs=headModel)\n","maxModel = Model(inputs=baseModel.input, outputs=maxModel)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84Qj4oWDQTDA"},"outputs":[],"source":["# compile our model\n","print(\"[INFO] compiling model...\")\n","#Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n","opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n","\tmetrics=[\"accuracy\"])\n","\n","maxModel.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_yHwHxKfKnjg"},"outputs":[],"source":["\t# train the head of the network\n","print(\"[INFO] training head Average Pooling Model...\")\n","H = model.fit(\n","\taug.flow(trainX, trainY, batch_size=BS),\n","\tsteps_per_epoch=len(trainX) // BS,\n","\tvalidation_data=(testX, testY),\n","\tvalidation_steps=len(testX) // BS,\n","\tepochs=EPOCHS)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxkAE8z3u9h5"},"outputs":[],"source":["\t# train the head of the network\n","print(\"[INFO] training head Max Pooling Model...\")\n","H_M = maxModel.fit(\n","\taug.flow(trainX, trainY, batch_size=BS),\n","\tsteps_per_epoch=len(trainX) // BS,\n","\tvalidation_data=(testX, testY),\n","\tvalidation_steps=len(testX) // BS,\n","\tepochs=EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjPEbctKQw0M"},"outputs":[],"source":["# make predictions on the testing set\n","print(\"[INFO] evaluating network...\")\n","predIdxs = model.predict(testX, batch_size=BS)\n","# for each image in the testing set we need to find the index of the\n","# label with corresponding largest predicted probability\n","predIdxs = np.argmax(predIdxs, axis=1)\n","\n","# show a nicely formatted classification report\n","print(classification_report(testY.argmax(axis=1), predIdxs,\n","\ttarget_names=lb.classes_))\n","\n","# make predictions on the testing set Max Pooling Model\n","print(\"[INFO] evaluating Max Pooling network...\")\n","predIdxsMax = maxModel.predict(testX, batch_size=BS)\n","# for each image in the testing set we need to find the index of the\n","# label with corresponding largest predicted probability\n","predIdxsMax = np.argmax(predIdxsMax, axis=1)\n","\n","# show a nicely formatted classification report\n","print(classification_report(testY.argmax(axis=1), predIdxsMax,\n","\ttarget_names=lb.classes_))\n","\n","\n","# serialize the model to disk\n","print(\"[INFO] saving smile detector model...\")\n","maxModel.save(\"drive/MyDrive/SS_MAX\", save_format=\"h5\")\n","model.save(\"drive/MyDrive/SS_AVERAGE\", save_format=\"h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0tGOXb34RSw_"},"outputs":[],"source":["# plot the training loss and accuracy\n","N = EPOCHS\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.figure(figsize=(18, 12))\n","plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.plot(np.arange(0, N), H_M.history[\"loss\"], label=\"train_loss_max\")\n","plt.plot(np.arange(0, N), H_M.history[\"val_loss\"], label=\"val_loss_max\")\n","plt.plot(np.arange(0, N), H_M.history[\"accuracy\"], label=\"train_acc_max\")\n","plt.plot(np.arange(0, N), H_M.history[\"val_accuracy\"], label=\"val_acc_max\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"lower left\")\n","plt.savefig(\"drive/MyDrive/plot.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FaXaiSgSLHep"},"outputs":[],"source":["# plot the training loss and accuracy\n","N = EPOCHS\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.figure(figsize=(18, 12))\n","plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"Validation accuracy by Average Pooling\")\n","plt.plot(np.arange(0, N), H_M.history[\"val_accuracy\"], label=\"Validation accuracy by  Max Pooling\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"lower left\")\n","plt.savefig(\"drive/MyDrive/val_plot.png\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
